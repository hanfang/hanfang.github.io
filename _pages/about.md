---
permalink: /
title: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Han Fang is a Research Scientist at Meta's SuperIntelligence Labs, with research interest in RL and agents. In 2023-2024, he led post-training of Llama 2 & 3, [debut Meta AI](https://developers.facebook.com/videos/2023/building-metas-next-generation-ai-product-experiences-with-llama/) and grew it to 1 billion MAU. He's been improving model’s general quality, growing. He drove the model integrated training runs, core capabilities, tool use and orchestration, and data flywheel. In 2025, he focuses on teaching models to think, reason, and use tools. ​

Han holds a PhD in Applied Mathematics and has published in top-tier venues with 9000+ citations. He is a recipient of the President’s Award to Distinguished Doctoral Students, the Woo-Jong Kim Dissertation Award, and the Excellence in Research Award.

[Google Scholar](https://scholar.google.com/citations?user=mQIqIVwAAAAJ) / [CV](/files/Han_Fang_CV.pdf) / [Linkedin](https://www.linkedin.com/in/hfang15/) / [Twitter](https://x.com/Han_Fang_)


Recent Papers
======
* **Generalized Parallel Scaling with Interdependent Generations**
  *Harry Dong, David Brandfonbrener, Eryk Helenowski, Yun He, Mrinal Kumar, **Han Fang**, Yuejie Chi, Karthik Abinav Sankararaman* · [**NeurIPS**](https://arxiv.org/abs/2510.01143) (2025)

* **Boosting LLM Reasoning via Spontaneous Self-Correction**
  *Xutong Zhao, Tengyu Xu, Xuewei Wang, Zhengxing Chen, Di Jin, Liang Tan, Zishun Yu, Zhuokai Zhao, Yun He, Sinong Wang, **Han Fang**, Sarath Chandar, Chen Zhu* · [**COLM**](https://arxiv.org/abs/2506.06923) (2025)

* **Learning Auxiliary Tasks Improves Reference-Free Hallucination Detection in Open-Domain Long-Form Generation**
  *Chengwei Qin, Wenxuan Zhou, Karthik Abinav Sankararaman, Nanshu Wang, Tengyu Xu, Alexander Radovic, Eryk Helenowski, Arya Talebzadeh, Aditya Tayade, Sinong Wang, Shafiq Joty, **Han Fang**, Hao Ma* · [**ACL**](https://arxiv.org/abs/2505.12265) (2025)

* **Think Smarter not Harder: Adaptive Reasoning with Inference Aware Optimization**
  *Zishun Yu, Tengyu Xu, Di Jin, Karthik Abinav Sankararaman, Yun He, Wenxuan Zhou, Zhouhao Zeng, Eryk Helenowski, Chen Zhu, Sinong Wang, Hao Ma, **Han Fang*** · [**ICML**](https://arxiv.org/abs/2501.17974) 2025

* **Step-KTO: Optimizing Mathematical Reasoning through Stepwise Binary Feedback**
  *Yen-Ting Lin, Di Jin, Tengyu Xu, Tianhao Wu, Sainbayar Sukhbaatar, Chen Zhu, Yun He, Yun-Nung Chen, Jason Weston, Yuandong Tian, Arash Rahnama, Sinong Wang, Hao Ma, **Han Fang*** · [arXiv](https://arxiv.org/abs/2501.10799) (2025)

* **Improving Model Factuality with Fine-grained Critique-based Evaluator**
  *Yiqing Xie, Wenxuan Zhou, Pradyot Prakash, Di Jin, Yuning Mao, Quintin Fettes, Arya Talebzadeh, Sinong Wang, **Han Fang**, Carolyn Rose, Daniel Fried, Hejia Zhang* · [**ACL**](https://arxiv.org/abs/2410.18359) 2025

* **Multi-IF: Benchmarking LLMs on Multi-Turn and Multilingual Instructions Following**
  *Yun He, Di Jin, Chaoqi Wang, Chloe Bi, Karishma Mandyam, Hejia Zhang, Chen Zhu, Ning Li, Tengyu Xu, Hongjiang Lv, Shruti Bhosale, Chenguang Zhu, Karthik Abinav Sankararaman, Eryk Helenowski, Melanie Kambadur, Aditya Tayade, Hao Ma, **Han Fang**, Sinong Wang* · [arXiv](https://arxiv.org/abs/2410.15553) 2024

* **The Perfect Blend: Redefining RLHF with mixture of judges**
  *Tengyu Xu, Eryk Helenowski, Karthik Abinav Sankararaman, Di Jin, Kaiyan Peng, Eric Han, Shaoliang Nie, Chen Zhu, Hejia Zhang, Wenxuan Zhou, Zhouhao Zeng, Yun He, Karishma Mandyam, Arya Talabzadeh, Madian Khabsa, Gabriel Cohen, Yuandong Tian, Hao Ma, Sinong Wang, **Han Fang*** · [arXiv](https://arxiv.org/abs/2409.20370) 2024

News
======

* **Meta AI reached MAU in Dec 2024 and in 1 billion MAU in May 2025**.
  Improved Meta AI's [multilinguality](https://about.fb.com/news/2024/07/meta-ai-is-now-multilingual-more-creative-and-smarter/), enabled the roll-out to 12 languages and 40+ countries. [Blog Post](https://ai.meta.com/blog/future-of-ai-built-with-llama/) / [News](https://techcrunch.com/2025/05/29/meta-ai-now-has-1b-monthly-active-users/) (2025)

* **Launched the voice mode and photo editing in Meta AI at Connect 2024**
  Launched an updated Llama 3 model for voice mode. Improved Planner to enable photo editing with mutimodal inputs. [Blog Post](https://about.fb.com/news/2024/09/metas-ai-product-news-connect/) (2024)

* **Launched [Llama 3 on Meta AI](https://ai.meta.com/blog/meta-llama-3/) and subsequently Llama 3.1**.
  Developed Meta AI's online RL with [Mixture of Judges](https://arxiv.org/abs/2409.20370), improving reasoning, instructions following, safety, etc. [Blog Post](https://ai.meta.com/blog/meta-llama-3-1/) (2024)

* **Launched [Meta AI](https://www.meta.ai/) with an improved Llama 2 model**.
  Debut [Meta AI](https://about.fb.com/news/2023/09/introducing-ai-powered-assistants-characters-and-creative-tools/) and launched Llama 2 into Family of Apps. Created Orchestrator for tool use, enabling search and image generation. Developed data flywheel for Reinforcement Learning from User Feedback. My talk at [Meta's Connect Conference](https://developers.facebook.com/videos/2023/building-metas-next-generation-ai-product-experiences-with-llama/) (2023)

* **Developed Meta AI Few-Shot Learner (FSL) that can adapt to new types of harmful content.**
  Developed FSL which can work in 100+ languages, learns from images & text, and detects new forms of violations. [Blog Post](https://ai.meta.com/blog/harmful-content-can-evolve-quickly-our-new-ai-system-adapts-to-tackle-it/) (2021)

* **Training AI to detect hate speech in the real world**
  Built a RL based framework to E2E optimize hate speech classifiers. [Blog Post](https://ai.meta.com/blog/training-ai-to-detect-hate-speech-in-the-real-world/) (2020)
